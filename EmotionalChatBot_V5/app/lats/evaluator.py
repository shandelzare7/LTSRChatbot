from __future__ import annotations

import re
from typing import Any, Dict, List, Optional, Tuple

from langchain_core.messages import HumanMessage, SystemMessage

from app.state import ProcessorPlan, ReplyPlan, SimReport
from utils.llm_json import parse_json_from_llm
from utils.detailed_logging import log_prompt_and_params, log_llm_response, log_computation

from app.lats.prompt_utils import (
    build_system_memory_block,
    get_chat_buffer_body_messages,
    safe_text,
    summarize_state_for_planner,
)


def _clamp(x: float, lo: float, hi: float) -> float:
    return max(lo, min(hi, x))


def _extract_keywords(text: str, min_keywords: int = 2, max_keywords: int = 4) -> List[str]:
    """
    ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼šæŒ‰å¸¸è§åˆ†éš”ç¬¦æ‹†åˆ†ï¼Œè¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯ï¼‰ã€‚
    è¿”å› 2~4 ä¸ªå…³é”®è¯ã€‚
    """
    import re
    # å¸¸è§åˆ†éš”ç¬¦
    separators = r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š\s,\.!?;:\n]+'
    words = re.split(separators, text.strip())
    
    # è¿‡æ»¤ï¼šé•¿åº¦ >= 2 çš„ä¸­æ–‡å­—ç¬¦æˆ–é•¿åº¦ >= 3 çš„è‹±æ–‡å•è¯
    keywords = []
    stop_words = {"çš„", "äº†", "æ˜¯", "åœ¨", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸€ä¸ª", "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°", "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "è¿™"}
    
    for word in words:
        word = word.strip()
        if not word:
            continue
        # ä¸­æ–‡å­—ç¬¦ï¼šè‡³å°‘2ä¸ªå­—ç¬¦
        if any('\u4e00' <= char <= '\u9fff' for char in word):
            if len(word) >= 2 and word not in stop_words:
                keywords.append(word)
        # è‹±æ–‡å•è¯ï¼šè‡³å°‘3ä¸ªå­—ç¬¦
        elif word.isalnum() and len(word) >= 3 and word.lower() not in {"the", "and", "for", "are", "but", "not", "you", "all", "can", "her", "was", "one", "our", "out", "day", "get", "has", "him", "his", "how", "man", "new", "now", "old", "see", "two", "way", "who", "boy", "did", "its", "let", "put", "say", "she", "too", "use"}:
            keywords.append(word.lower())
        
        if len(keywords) >= max_keywords:
            break
    
    # å¦‚æœå…³é”®è¯å¤ªå°‘ï¼Œè‡³å°‘è¿”å›åŸå§‹æ–‡æœ¬çš„å‰å‡ ä¸ªå­—ç¬¦
    if len(keywords) < min_keywords:
        # å–å‰2-4ä¸ªéç©ºå­—ç¬¦ä½œä¸ºå…³é”®è¯
        chars = [c for c in text if c.strip() and not c.isspace()]
        if chars:
            step = max(1, len(chars) // max_keywords)
            keywords = [''.join(chars[i:i+step]) for i in range(0, min(len(chars), max_keywords * step), step)][:max_keywords]
    
    return keywords[:max_keywords]


def hard_gate(
    processor_plan: ProcessorPlan,
    requirements: Dict[str, Any],
) -> List[Dict[str, str]]:
    """
    ç¡¬é—¨æ§ï¼šåªåš"ç»“æ„ç¡¬çº¦æŸ"ï¼Œmust_have ä¸å†ç¡¬å¤±è´¥ï¼ˆç§»åˆ° soft scoreï¼‰ã€‚
    
    ç¡¬çº¦æŸåªä¿ç•™ä¸‰ç±»ï¼š
    1. ç»“æ„ï¼šæ¶ˆæ¯æ•°ã€ç©ºæ¶ˆæ¯ï¼ˆä½† mute å…è®¸ç©ºï¼‰ã€å•æ¡é•¿åº¦
    2. ç¦è¯ï¼šå¼ºåŠ©æ‰‹æ¨¡æ¿ï¼ˆ"ä½œä¸ºAIâ€¦/æ„Ÿè°¢ä½¿ç”¨/ç¥æ‚¨ä½¿ç”¨æ„‰å¿«â€¦"ï¼‰
    3. é¦–æ¡æœ€å°é•¿åº¦ï¼šä»…åœ¨ allow_short_reply=False æ—¶å¯ç”¨
    """
    fails: List[Dict[str, str]] = []
    msgs = processor_plan.get("messages") or []
    
    # è®°å½•ç¡¬é—¨æ§›æ£€æŸ¥è¿‡ç¨‹
    log_computation(
        "Evaluator",
        "ç¡¬é—¨æ§›æ£€æŸ¥ (Hard Gate)",
        inputs={
            "processor_plan": {
                "messages_count": len(msgs),
                "messages_preview": [str(m)[:50] for m in msgs[:3]],
                "delays": processor_plan.get("delays", []),
            },
            "requirements": requirements,
        },
    )
    
    # è¯»å– requirements_policy
    allow_empty_reply = bool(requirements.get("allow_empty_reply", False))
    allow_short_reply = bool(requirements.get("allow_short_reply", False))

    # ==========================================
    # 1. ç»“æ„ç¡¬çº¦æŸï¼šç©ºæ¶ˆæ¯æ£€æŸ¥ï¼ˆmode æ”¾å®½ï¼‰
    # ==========================================
    if not isinstance(msgs, list) or not msgs:
        if allow_empty_reply:
            # mute_mode å…è®¸ç©ºå›å¤ï¼Œç›´æ¥é€šè¿‡
            log_computation("Evaluator", "ç¡¬é—¨æ§›æ£€æŸ¥ç»“æœ", outputs={"failed_checks": [], "passed": True})
            return []
        else:
            result = [{"id": "empty", "reason": "messages ä¸ºç©º", "evidence": ""}]
            log_computation("Evaluator", "ç¡¬é—¨æ§›æ£€æŸ¥ç»“æœ", outputs={"failed_checks": result})
            return result

    # ==========================================
    # 2. ç»“æ„ç¡¬çº¦æŸï¼šæ¶ˆæ¯æ•°æ£€æŸ¥
    # ==========================================
    max_messages = int(requirements.get("max_messages", 5) or 5)
    if len(msgs) > max_messages:
        fails.append(
            {
                "id": "too_many_messages",
                "reason": f"æ¶ˆæ¯æ¡æ•°è¶…ä¸Šé™({len(msgs)}>{max_messages})",
                "evidence": "",
            }
        )

    # ==========================================
    # 3. ç»“æ„ç¡¬çº¦æŸï¼šå•æ¡æ¶ˆæ¯é•¿åº¦æ£€æŸ¥
    # ==========================================
    max_len = int(requirements.get("max_message_len", 200) or 200)
    for i, m in enumerate(msgs):
        t = str(m or "").strip()
        # ç©ºæ¶ˆæ¯æ£€æŸ¥ï¼ˆmode æ”¾å®½ï¼‰
        if not t:
            if not allow_empty_reply:
                fails.append({"id": "empty_message", "reason": f"ç¬¬{i+1}æ¡ä¸ºç©º", "evidence": ""})
        # é•¿åº¦æ£€æŸ¥
        if len(t) > max_len:
            fails.append(
                {
                    "id": "message_too_long",
                    "reason": f"ç¬¬{i+1}æ¡è¿‡é•¿({len(t)}>{max_len})",
                    "evidence": t[:120],
                }
            )

    # ==========================================
    # 4. ç»“æ„ç¡¬çº¦æŸï¼šé¦–æ¡æœ€å°é•¿åº¦ï¼ˆmode æ”¾å®½ï¼‰
    # ==========================================
    if not allow_short_reply:
        min_first_len = int(requirements.get("min_first_len", 8) or 8)
        first = str(msgs[0] or "").strip()
        if len(first) < min_first_len:
            fails.append(
                {
                    "id": "first_too_short",
                    "reason": f"é¦–æ¡è¿‡çŸ­({len(first)}<{min_first_len})ï¼Œå¯èƒ½åƒé“ºå«/åºŸè¯",
                    "evidence": first,
                }
            )
    # allow_short_reply=True æ—¶è·³è¿‡é¦–æ¡é•¿åº¦æ£€æŸ¥ï¼ˆcold_mode å…è®¸çŸ­å›å¤ï¼‰

    # ==========================================
    # 5. ç¦è¯ç¡¬çº¦æŸï¼šrequirements.forbiddenï¼ˆé«˜æƒé‡è¿ç¦è¯ï¼‰
    # ==========================================
    forbidden_terms = requirements.get("forbidden") or []
    if isinstance(forbidden_terms, list) and forbidden_terms:
        all_text_forbidden = "\n".join([str(m) for m in msgs])
        for term in forbidden_terms:
            t = str(term or "").strip()
            if not t:
                continue
            # è¿™é‡Œä½¿ç”¨â€œåŒ…å«â€è€Œéæ­£åˆ™ï¼šé¿å…è¯¯ä¼¤/å¤æ‚åº¦ï¼›æ²‰æµ¸ç ´åè¯å°±æ˜¯è¦å¼ºç¡¬æ·˜æ±°
            if t.lower() in all_text_forbidden.lower():
                fails.append(
                    {
                        "id": "forbidden_term",
                        "reason": f"å‘½ä¸­è¿ç¦è¯ï¼š'{t}'ï¼ˆæ²‰æµ¸ç ´å/æ¨¡æ¿åŒ–é£é™©é«˜ï¼‰",
                        "evidence": all_text_forbidden[:240],
                    }
                )
                break

    # ==========================================
    # 6. ç¦è¯ç¡¬çº¦æŸï¼šå¼ºåŠ©æ‰‹æ¨¡æ¿ï¼ˆèº«ä»½è¯ + å®¢æœå¥å¼ï¼‰
    # ==========================================
    # èº«ä»½è¯ï¼šæ˜ç¡®è‡ªç§°AI/åŠ©æ‰‹/æœºå™¨äºº
    identity_patterns = [
        # ç›´æ¥è‡ªç§°
        r"æˆ‘æ˜¯\s*(ai|äººå·¥æ™ºèƒ½|æ™ºèƒ½åŠ©æ‰‹|æœºå™¨äººåŠ©æ‰‹|chatbot|åŠ©æ‰‹)",
        r"æˆ‘æ˜¯ä¸€ä¸ª\s*(ai|äººå·¥æ™ºèƒ½|æ™ºèƒ½åŠ©æ‰‹|æœºå™¨äººåŠ©æ‰‹|chatbot|åŠ©æ‰‹)",
        r"ä½œä¸º\s*(ai|äººå·¥æ™ºèƒ½|æ™ºèƒ½åŠ©æ‰‹|æœºå™¨äººåŠ©æ‰‹|chatbot|åŠ©æ‰‹)",
        r"æˆ‘æ˜¯\s*(ai|äººå·¥æ™ºèƒ½|æ™ºèƒ½åŠ©æ‰‹|æœºå™¨äººåŠ©æ‰‹|chatbot|åŠ©æ‰‹)\s*ï¼Œ",
        r"æˆ‘æ˜¯\s*(ai|äººå·¥æ™ºèƒ½|æ™ºèƒ½åŠ©æ‰‹|æœºå™¨äººåŠ©æ‰‹|chatbot|åŠ©æ‰‹)\s*ã€‚",
        # å®½æ¾è‡ªç§°ï¼šå…è®¸ä¸­é—´æ’å…¥åå­—/å®šè¯­ï¼ˆä¿®å¤ï¼šå¦‚â€œæˆ‘æ˜¯å°æ± ï¼Œä¸€ä¸ªå¯ä»¥é™ªä½ èŠå¤©çš„åŠ©æ‰‹â€ï¼‰
        r"æˆ‘\s*æ˜¯[\s\S]{0,24}(ai|äººå·¥æ™ºèƒ½|æ™ºèƒ½åŠ©æ‰‹|æœºå™¨äººåŠ©æ‰‹|chatbot|åŠ©æ‰‹)",
        r"(æˆ‘å«|æˆ‘æ˜¯|å«æˆ‘)[\s\S]{0,18}(ä¸€ä¸ª|ä½)?[\s\S]{0,18}(ai|äººå·¥æ™ºèƒ½|æ™ºèƒ½åŠ©æ‰‹|æœºå™¨äººåŠ©æ‰‹|chatbot|èŠå¤©åŠ©æ‰‹|åŠ©æ‰‹)",
    ]
    
    # å®¢æœå¥å¼ï¼šäº§å“è¯´æ˜å¼æ¨¡æ¿å¥ï¼ˆä¸æ˜¯å…¨ç¦"å¸®ä½ "ï¼Œè€Œæ˜¯ç¦è¿™ç±»æ¨¡æ¿å¥ï¼‰
    service_patterns = [
        r"æˆ‘å¯ä»¥å¸®ä½ \s*(è§£ç­”é—®é¢˜|è§£å†³é—®é¢˜|æä¾›ä¿¡æ¯|åšä»€ä¹ˆ|åšä»€ä¹ˆå—)",
        r"æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ ",
        r"æœ‰ä»€ä¹ˆå¯ä»¥\s*å¸®ä½ ",
        r"éœ€è¦æˆ‘å¸®ä½ \s*(åšä»€ä¹ˆ|è§£å†³|è§£ç­”)",
        r"æˆ‘èƒ½ä¸ºä½ \s*(åšä»€ä¹ˆ|æä¾›|è§£ç­”)",
        r"æˆ‘èƒ½å¸®ä½ \s*(è§£ç­”é—®é¢˜|è§£å†³é—®é¢˜|æä¾›ä¿¡æ¯|åšä»€ä¹ˆ|åšä»€ä¹ˆå—)",
        r"æˆ‘å¯ä»¥ä¸ºä½ \s*(åšä»€ä¹ˆ|æä¾›|è§£ç­”)",
        r"æœ‰ä»€ä¹ˆéœ€è¦æˆ‘\s*(å¸®ä½ |ä¸ºä½ |ååŠ©)",
        r"æˆ‘å¯ä»¥\s*(ä¸ºä½ |å¸®ä½ )\s*(åšä»€ä¹ˆ|æä¾›|è§£ç­”)",
    ]
    
    all_text = "\n".join([str(m) for m in msgs])
    all_text_lower = all_text.lower()
    
    # æ£€æŸ¥èº«ä»½è¯ï¼ˆä½¿ç”¨æ­£åˆ™åŒ¹é…ï¼‰
    if not fails:  # è‹¥å·²å‘½ä¸­ forbidden_termï¼Œåˆ™ä¸å†ç»§ç»­æ£€æŸ¥ï¼ˆé¿å…é‡å¤å¤±è´¥åŸå› ï¼‰
        for pattern in identity_patterns:
            if re.search(pattern, all_text_lower):
                matched = re.search(pattern, all_text_lower)
                matched_text = matched.group(0) if matched else pattern
                fails.append(
                    {
                        "id": "assistant_like_response",
                        "reason": f"æ£€æµ‹åˆ°èº«ä»½è¯æ¨¡å¼ï¼š'{matched_text}'ï¼ˆè‡ªç§°AI/åŠ©æ‰‹/æœºå™¨äººï¼‰ï¼Œä¸ç¬¦åˆæ‹ŸäººåŒ–è¦æ±‚",
                        "evidence": all_text[:200],
                    }
                )
                break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†
    
    # æ£€æŸ¥å®¢æœå¥å¼ï¼ˆä½¿ç”¨æ­£åˆ™åŒ¹é…ï¼‰
    if not fails:  # å¦‚æœå‰é¢æ²¡å¤±è´¥ï¼Œå†æ£€æŸ¥å®¢æœå¥å¼
        for pattern in service_patterns:
            if re.search(pattern, all_text_lower):
                matched = re.search(pattern, all_text_lower)
                matched_text = matched.group(0) if matched else pattern
                fails.append(
                    {
                        "id": "assistant_like_response",
                        "reason": f"æ£€æµ‹åˆ°å®¢æœå¥å¼ï¼š'{matched_text}'ï¼ˆäº§å“è¯´æ˜å¼æ¨¡æ¿å¥ï¼‰ï¼Œä¸ç¬¦åˆæ‹ŸäººåŒ–è¦æ±‚",
                        "evidence": all_text[:200],
                    }
                )
                break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†

    # ==========================================
    # 7. P0ï¼šæ— è¯·æ±‚çš„å»ºè®®/æ•™ç¨‹ç¡¬çº¦æŸï¼ˆspeech_act/å£å»å…ˆéªŒï¼‰
    # - é™¤éç”¨æˆ·æ˜ç¡® asking-for-adviceï¼Œå¦åˆ™â€œæˆ‘å»ºè®®/ä½ åº”è¯¥/æ­¥éª¤å¦‚ä¸‹/æ€»ç»“ä¸€ä¸‹â€ç­‰æŒ‡ä»¤å¼è¯æœ¯ç›´æ¥åˆ¤è´Ÿ
    # ==========================================
    if not fails:
        user_asks_advice = bool(requirements.get("user_asks_advice", False))
        latest_user_text = str(requirements.get("latest_user_text") or "")
        # å…œåº•ï¼šè‹¥ä¸Šæ¸¸æ²¡å¡«ï¼Œä¹Ÿå¯ç”¨æ–‡æœ¬å¼±åˆ¤æ–­
        if not user_asks_advice and latest_user_text:
            if re.search(r"(å»ºè®®|æ¨è|æ­¥éª¤|æ•™ç¨‹|æ€ä¹ˆ|å¦‚ä½•|æ•™æˆ‘|è¯·æ•™|å¸®æˆ‘)", latest_user_text, re.IGNORECASE):
                user_asks_advice = True

        unsolicited_advice_patterns = [
            r"æˆ‘å»ºè®®",
            r"å»ºè®®ä½ ",
            r"ä½ åº”è¯¥",
            r"ä½ å¯ä»¥(è¿™æ ·|å…ˆ|è¯•è¯•|è€ƒè™‘)",
            r"æ­¥éª¤å¦‚ä¸‹",
            r"(ç¬¬ä¸€|é¦–å…ˆ).{0,12}(ç¬¬äºŒ|å…¶æ¬¡|ç„¶å)",
            r"æ€»ç»“ä¸€ä¸‹",
            r"ç»™ä½ (å‡ ä¸ª|ä¸‰ç‚¹|å‡ ç‚¹)å»ºè®®",
        ]
        if not user_asks_advice:
            for pattern in unsolicited_advice_patterns:
                if re.search(pattern, all_text, re.IGNORECASE):
                    matched = re.search(pattern, all_text, re.IGNORECASE)
                    matched_text = matched.group(0) if matched else pattern
                    fails.append(
                        {
                            "id": "unsolicited_advice",
                            "reason": f"æœªè¢«è¯·æ±‚å´å‡ºç°å»ºè®®/æ•™ç¨‹å¼å£å»ï¼š'{matched_text}'ï¼ˆå®¹æ˜“å˜åŠ©æ‰‹ï¼‰",
                            "evidence": all_text[:220],
                        }
                    )
                    break
    
    # é¢å¤–çš„æ¨¡æ¿åŒ–ç»“è¯­æ£€æŸ¥ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    template_endings = [
        "æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨", "ç¥æ‚¨ä½¿ç”¨æ„‰å¿«", "å¦‚æœ‰é—®é¢˜è¯·éšæ—¶", "æ¬¢è¿éšæ—¶å’¨è¯¢",
    ]
    for pattern in template_endings:
        if pattern in all_text_lower:
            fails.append(
                {
                    "id": "assistant_like_response",
                    "reason": f"æ£€æµ‹åˆ°æ¨¡æ¿åŒ–ç»“è¯­ï¼š'{pattern}'ï¼Œä¸ç¬¦åˆæ‹ŸäººåŒ–è¦æ±‚",
                    "evidence": all_text[:200],
                }
            )
            break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†

    # æ³¨æ„ï¼šmust_have æ£€æŸ¥å·²ç§»é™¤ï¼Œç§»åˆ° soft_score ä¸­å¤„ç†

    log_computation(
        "Evaluator",
        "ç¡¬é—¨æ§›æ£€æŸ¥ç»“æœ",
        outputs={
            "failed_checks": fails,
            "passed": len(fails) == 0,
        },
    )
    return fails


def check_assistant_like_via_llm(
    messages: List[Any],
    llm_invoker: Any,
) -> Optional[Tuple[bool, float]]:
    """
    è½»é‡çº§ LLM classifierï¼šæ£€æµ‹åŠ©æ‰‹å¼å›ç­”ã€‚
    è¿”å› (is_assistant_like: bool, confidence: float) æˆ– Noneï¼ˆå¦‚æœå‡ºé”™ï¼‰ã€‚
    """
    if llm_invoker is None:
        return None
    
    msgs_text = "\n".join([str(m) for m in messages])
    if not msgs_text.strip():
        return None
    
    # è½»é‡çº§ promptï¼Œåªæ£€æŸ¥åŠ©æ‰‹å¼å›ç­”
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹å¼å›ç­”æ£€æµ‹å™¨ã€‚åˆ¤æ–­ç»™å®šçš„å›å¤æ˜¯å¦åƒAIåŠ©æ‰‹æˆ–å®¢æœï¼Œè€Œä¸æ˜¯çœŸäººæœ‹å‹èŠå¤©ã€‚

åŠ©æ‰‹å¼å›ç­”ç‰¹å¾ï¼š
- ä½¿ç”¨"æˆ‘åœ¨è¿™é‡Œå¸®åŠ©ä½ "ã€"æä¾›ä¿¡æ¯"ã€"ä¸ºæ‚¨æœåŠ¡"ã€"æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨"ç­‰è¡¨è¿°
- è¯­æ°”æ­£å¼ã€ç¤¼è²Œä½†ç¼ºä¹çœŸå®æƒ…æ„Ÿ
- åƒå®¢æœæˆ–AIåŠ©æ‰‹ï¼Œè€Œä¸æ˜¯æœ‹å‹é—´çš„è‡ªç„¶å¯¹è¯

åªè¾“å‡º JSONï¼š
{
  "assistant_like": true/false,
  "confidence": 0.0-1.0
}"""
    
    user_prompt = f"""åˆ¤æ–­ä»¥ä¸‹å›å¤æ˜¯å¦æ˜¯åŠ©æ‰‹å¼å›ç­”ï¼š

{msgs_text[:500]}"""
    
    try:
        resp = llm_invoker.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])
        content = getattr(resp, "content", "") or ""
        data = parse_json_from_llm(content)
        if isinstance(data, dict):
            is_assistant = bool(data.get("assistant_like", False))
            confidence = float(data.get("confidence", 0.5) or 0.5)
            confidence = _clamp(confidence, 0.0, 1.0)
            
            log_prompt_and_params(
                "Evaluator (Assistant-Like Classifier)",
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                messages=[],
                params={"messages_preview": msgs_text[:200]}
            )
            log_llm_response("Evaluator (Assistant-Like Classifier)", resp, parsed_result=data)
            
            return is_assistant, confidence
    except Exception as e:
        log_computation(
            "Evaluator",
            "LLMåŠ©æ‰‹å¼å›ç­”æ£€æµ‹å¤±è´¥",
            inputs={"error": str(e)[:100]},
            outputs={"fallback": True}
        )
    
    return None


def _compute_plan_coverage(
    msgs: List[str],
    plan_goals: Dict[str, Any],
) -> float:
    """
    è®¡ç®— plan_coverageï¼šå†…å®¹å±‚æ˜¯å¦ç¬¦åˆ reasoner çš„ plan_goals.must_cover_pointsã€‚
    
    Args:
        msgs: æ¶ˆæ¯åˆ—è¡¨
        plan_goals: {"must_cover_points": List[str], "avoid_points": List[str]}
    
    Returns:
        coverage: 0.0-1.0ï¼Œè¦†ç›–ç‡
    """
    must_cover_points = plan_goals.get("must_cover_points", [])
    if not must_cover_points:
        return 1.0  # æ²¡æœ‰è¦æ±‚ï¼Œé»˜è®¤æ»¡åˆ†
    
    # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯æ–‡æœ¬
    joined = "\n".join([str(m) for m in msgs]).lower()
    
    covered = 0
    total = len(must_cover_points)
    
    for point in must_cover_points:
        s = str(point or "").strip()
        if not s:
            continue
        
        # æå–å…³é”®è¯
        keywords = _extract_keywords(s, min_keywords=2, max_keywords=4)
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€åŠå…³é”®è¯åœ¨ joined ä¸­
        matched_keywords = sum(1 for kw in keywords if kw.lower() in joined)
        if matched_keywords >= max(1, len(keywords) // 2):
            covered += 1
    
    if total > 0:
        coverage = covered / total
    else:
        coverage = 1.0
    
    return _clamp(coverage, 0.0, 1.0)


def _compute_style_distance(
    msgs: List[str],
    style_targets: Dict[str, float],
) -> float:
    """
    è®¡ç®— style_distanceï¼šè¡¨è¾¾å±‚æ˜¯å¦ç¬¦åˆ style 12 ç»´ç›®æ ‡ã€‚
    
    ä½¿ç”¨ 3-5 ä¸ªå¯è§‚æµ‹ä»£ç†æ¥ä¼°ç®— style ç»´åº¦ï¼š
    - verbal_length: æ¶ˆæ¯é•¿åº¦/æ€»å­—æ•°åŒºé—´
    - social_distance: ç§°å‘¼ã€æ•¬è¯­ã€ä½ æˆ‘è·ç¦»è¯
    - emotional_display: æƒ…ç»ªè¯å¯†åº¦ã€æ„Ÿå¹å·ã€æƒ…ç»ªæ ‡è®°
    - wit_and_humor: æ˜¯å¦å‡ºç°è½»å¾®ç©ç¬‘ç»“æ„
    - non_verbal_cues: æ‹¬å·åŠ¨ä½œ/è¡¨æƒ…åŒ…ç¬¦å·
    
    Args:
        msgs: æ¶ˆæ¯åˆ—è¡¨
        style_targets: {"verbal_length": 0.15, "social_distance": 0.70, ...}
    
    Returns:
        style_match: 0.0-1.0ï¼Œ1.0 è¡¨ç¤ºå®Œå…¨åŒ¹é…ï¼Œ0.0 è¡¨ç¤ºå®Œå…¨ä¸åŒ¹é…
    """
    if not msgs:
        return 0.5  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
    
    # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯æ–‡æœ¬
    all_text = "\n".join([str(m) for m in msgs])
    total_chars = len(all_text)
    total_words = len(all_text.split())
    
    observed: Dict[str, float] = {}
    
    # ==========================================
    # 1. verbal_length: æ¶ˆæ¯é•¿åº¦/æ€»å­—æ•°åŒºé—´
    # ==========================================
    if "verbal_length" in style_targets:
        # å°†æ€»å­—ç¬¦æ•°æ˜ å°„åˆ° 0-1 èŒƒå›´ï¼ˆå‡è®¾ 0-500 å­—ç¬¦å¯¹åº” 0-1ï¼‰
        # æ›´é•¿çš„æ–‡æœ¬å¯¹åº”æ›´é«˜çš„ verbal_length
        max_chars = 500.0
        observed["verbal_length"] = _clamp(total_chars / max_chars, 0.0, 1.0)
    
    # ==========================================
    # 2. social_distance: ç§°å‘¼ã€æ•¬è¯­ã€ä½ æˆ‘è·ç¦»è¯
    # ==========================================
    if "social_distance" in style_targets:
        # è·ç¦»è¯ï¼ˆæ›´è¿œï¼‰ï¼š"ä½ çˆ±æ€æ ·æ€æ ·"ã€"éšä½ "ã€"æ— æ‰€è°“"ã€"éšä¾¿"ã€"éƒ½å¯ä»¥"
        # æ•¬è¯­ï¼ˆæ›´è¿œï¼‰ï¼š"æ‚¨"ã€"è¯·"ã€"éº»çƒ¦"ã€"æ„Ÿè°¢"
        # äº²å¯†è¯ï¼ˆæ›´è¿‘ï¼‰ï¼š"å’±"ã€"å’±ä»¬"ã€"ä¸€èµ·"ã€"æˆ‘ä»¬"
        distance_words = ["éšä½ ", "éšä¾¿", "éƒ½å¯ä»¥", "æ— æ‰€è°“", "ä½ çˆ±", "æ‚¨", "è¯·", "éº»çƒ¦", "æ„Ÿè°¢", "è°¢è°¢"]
        intimate_words = ["å’±", "å’±ä»¬", "ä¸€èµ·", "æˆ‘ä»¬", "å’±ä¿©"]
        
        distance_count = sum(1 for word in distance_words if word in all_text)
        intimate_count = sum(1 for word in intimate_words if word in all_text)
        
        # è®¡ç®—ç¤¾äº¤è·ç¦»ï¼šdistance_count å¢åŠ è·ç¦»ï¼Œintimate_count å‡å°‘è·ç¦»
        # å½’ä¸€åŒ–åˆ° 0-1ï¼ˆå‡è®¾æœ€å¤š 5 ä¸ªè·ç¦»è¯æˆ–äº²å¯†è¯ï¼‰
        max_markers = 5.0
        distance_score = _clamp(distance_count / max_markers, 0.0, 1.0)
        intimate_score = _clamp(intimate_count / max_markers, 0.0, 1.0)
        
        # social_distance = 0.5 + 0.3 * distance_score - 0.2 * intimate_score
        observed["social_distance"] = _clamp(0.5 + 0.3 * distance_score - 0.2 * intimate_score, 0.0, 1.0)
    
    # ==========================================
    # 3. emotional_display: æƒ…ç»ªè¯å¯†åº¦ã€æ„Ÿå¹å·ã€æƒ…ç»ªæ ‡è®°
    # ==========================================
    if "emotional_display" in style_targets:
        # æƒ…ç»ªè¯ï¼šæ„Ÿå¹è¯ã€æƒ…ç»ªå½¢å®¹è¯
        emotion_words = ["ï¼", "!", "ï¼Ÿ", "?", "å“ˆå“ˆ", "å‘µå‘µ", "å”‰", "å•Š", "å“¦", "å—¯", "å“‡", "å¤©", "å¥½", "å¤ª", "çœŸçš„", "ç¡®å®"]
        emotion_markers = ["ğŸ˜Š", "ğŸ˜¢", "ğŸ˜¡", "ğŸ˜„", "ğŸ˜­", "ğŸ˜¤", "ğŸ˜…", "ğŸ˜‚", "ğŸ˜", "ğŸ˜˜", "ğŸ˜", "ğŸ˜", "ğŸ˜’", "ğŸ˜”", "ğŸ˜•", "ğŸ˜–"]
        
        emotion_count = sum(1 for word in emotion_words if word in all_text)
        marker_count = sum(1 for marker in emotion_markers if marker in all_text)
        
        # è®¡ç®—æƒ…ç»ªå¯†åº¦ï¼šæƒ…ç»ªè¯å’Œæ ‡è®°çš„æ•°é‡ / æ€»å­—ç¬¦æ•° * 100
        # å½’ä¸€åŒ–åˆ° 0-1ï¼ˆå‡è®¾ 0-20 ä¸ªæƒ…ç»ªæ ‡è®°å¯¹åº” 0-1ï¼‰
        max_emotion_markers = 20.0
        emotion_density = _clamp((emotion_count + marker_count * 2) / max_emotion_markers, 0.0, 1.0)
        
        observed["emotional_display"] = emotion_density
    
    # ==========================================
    # 4. wit_and_humor: æ˜¯å¦å‡ºç°è½»å¾®ç©ç¬‘ç»“æ„
    # ==========================================
    if "wit_and_humor" in style_targets:
        # ç©ç¬‘ç»“æ„ï¼šåé—®ã€è½»è®½ã€åŒå…³ç¬¦å·
        humor_patterns = ["ï¼Ÿ", "?", "å“ˆå“ˆ", "å˜¿å˜¿", "å˜»å˜»", "ï½", "~", "ï¼ˆç¬‘", "ï¼ˆ", "ï¼‰", ")", "ï¼ˆ", "ï¼‰"]
        # åé—®å¥ï¼šåŒ…å«"ä¸æ˜¯"ã€"éš¾é“"ã€"æ€ä¹ˆ"ã€"ä¸ºä»€ä¹ˆ"ç­‰
        rhetorical_words = ["ä¸æ˜¯", "éš¾é“", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "ä¸ºå•¥", "ä½•ä¸", "ä½•å°"]
        
        humor_count = sum(1 for pattern in humor_patterns if pattern in all_text)
        rhetorical_count = sum(1 for word in rhetorical_words if word in all_text)
        
        # å½’ä¸€åŒ–åˆ° 0-1ï¼ˆå‡è®¾æœ€å¤š 5 ä¸ªå¹½é»˜æ ‡è®°ï¼‰
        max_humor_markers = 5.0
        humor_score = _clamp((humor_count + rhetorical_count) / max_humor_markers, 0.0, 1.0)
        
        observed["wit_and_humor"] = humor_score
    
    # ==========================================
    # 5. non_verbal_cues: æ‹¬å·åŠ¨ä½œ/è¡¨æƒ…åŒ…ç¬¦å·
    # ==========================================
    if "non_verbal_cues" in style_targets:
        # æ‹¬å·åŠ¨ä½œï¼š"(ç¬‘"ã€"(æ‘Šæ‰‹"ã€"(è€¸è‚©"ã€"(æ‘‡å¤´"ç­‰
        # è¡¨æƒ…åŒ…ç¬¦å·ï¼šemojiã€é¢œæ–‡å­—ç­‰
        paren_actions = re.findall(r'[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]', all_text)
        emoji_pattern = r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000027BF]'
        emojis = re.findall(emoji_pattern, all_text)
        
        cue_count = len(paren_actions) + len(emojis)
        
        # å½’ä¸€åŒ–åˆ° 0-1ï¼ˆå‡è®¾æœ€å¤š 10 ä¸ªéè¯­è¨€ cuesï¼‰
        max_cues = 10.0
        cue_score = _clamp(cue_count / max_cues, 0.0, 1.0)
        
        observed["non_verbal_cues"] = cue_score
    
    # ==========================================
    # è®¡ç®— style_match = 1.0 - mean(abs(observed[d] - target[d]) for d in dims_used)
    # ==========================================
    dims_used = []
    distances = []
    
    for dim in ["verbal_length", "social_distance", "emotional_display", "wit_and_humor", "non_verbal_cues"]:
        if dim in style_targets and dim in observed:
            target_val = float(style_targets[dim])
            observed_val = float(observed[dim])
            distance = abs(observed_val - target_val)
            distances.append(distance)
            dims_used.append(dim)
    
    if not distances:
        return 0.5  # æ²¡æœ‰å¯ç”¨çš„ç»´åº¦ï¼Œè¿”å›ä¸­ç­‰åˆ†æ•°
    
    mean_distance = sum(distances) / len(distances)
    style_match = 1.0 - mean_distance
    
    return _clamp(style_match, 0.0, 1.0)


def _compute_stage_fit_heur(
    msgs: List[str],
    stage_targets: Dict[str, Any],
    detection_signals: Dict[str, Any],
) -> float:
    """
    è®¡ç®— stage_fit_heurï¼šé˜¶æ®µé€‚é…åº¦ã€‚
    
    ä½¿ç”¨ stage_targets.pacing_notes + stage_ctxï¼ˆè¶Šç•Œæ£€æµ‹ï¼‰ï¼š
    - å¦‚æœ stage_ctx é«˜ï¼ˆè¶Šç•Œæ˜æ˜¾ï¼‰ï¼Œè€Œè¾“å‡ºè¿˜åœ¨æ¨è¿›äº²å¯†/æ·±æŒ–éšç§ â†’ ç›´æ¥æ‰£åˆ†
    - initiating é˜¶æ®µï¼šé¿å…"æˆ‘ä»¬å¾ˆç†Ÿ/ä½ åº”è¯¥â€¦"è¿™ç§æ¨è¿›
    
    Args:
        msgs: æ¶ˆæ¯åˆ—è¡¨
        stage_targets: {"stage": str, "pacing_notes": List[str], "violation_sensitivity": float}
        detection_signals: åŒ…å« stage_ctx çš„æ£€æµ‹ä¿¡å·
    
    Returns:
        stage_fit: 0.0-1.0ï¼Œ1.0 è¡¨ç¤ºå®Œå…¨é€‚é…ï¼Œ0.0 è¡¨ç¤ºå®Œå…¨ä¸é€‚é…
    """
    if not msgs:
        return 0.5  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
    
    # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯æ–‡æœ¬
    all_text = "\n".join([str(m) for m in msgs]).lower()
    stage = stage_targets.get("stage", "").lower()
    
    # è·å– stage_ctxï¼ˆè¶Šç•Œæ£€æµ‹ä¿¡å·ï¼‰
    stage_ctx = detection_signals.get("stage_ctx", {})
    if isinstance(stage_ctx, dict):
        # è®¡ç®—æœ€å¤§è¶Šç•Œå€¼
        max_violation = max([float(v) for v in stage_ctx.values() if isinstance(v, (int, float))], default=0.0)
    else:
        max_violation = 0.0
    
    violation_sensitivity = float(stage_targets.get("violation_sensitivity", 0.7) or 0.7)
    
    # åŸºç¡€åˆ†æ•°
    base_score = 1.0
    
    # ==========================================
    # 1. æ£€æŸ¥è¶Šç•Œè¡Œä¸ºï¼šå¦‚æœ stage_ctx é«˜ï¼Œè€Œè¾“å‡ºè¿˜åœ¨æ¨è¿›äº²å¯†/æ·±æŒ–éšç§ â†’ æ‰£åˆ†
    # ==========================================
    if max_violation > 0.5:  # è¶Šç•Œæ˜æ˜¾
        # æ£€æµ‹æ¨è¿›äº²å¯†çš„è¯æ±‡
        intimacy_promotion_words = [
            "æˆ‘ä»¬å¾ˆç†Ÿ", "æˆ‘ä»¬åº”è¯¥", "ä½ åº”è¯¥", "ä½ å¿…é¡»", "ä½ å¾—",
            "æˆ‘ä»¬", "å’±ä»¬", "ä¸€èµ·", "å’±ä¿©", "å’±",
            "æ·±æŒ–", "æ·±å…¥", "éšç§", "ç§˜å¯†", "å‘Šè¯‰æˆ‘", "è¯´è¯´",
            "ä½ å¿ƒé‡Œ", "ä½ å†…å¿ƒ", "ä½ çœŸå®", "ä½ çœŸæ­£",
        ]
        
        intimacy_count = sum(1 for word in intimacy_promotion_words if word in all_text)
        
        if intimacy_count > 0:
            # è¶Šç•Œæ˜æ˜¾ä¸”è¿˜åœ¨æ¨è¿›äº²å¯†ï¼Œå¤§å¹…æ‰£åˆ†
            penalty = min(0.8, max_violation * 0.5 + intimacy_count * 0.1)
            base_score -= penalty
    
    # ==========================================
    # 2. é˜¶æ®µç‰¹å®šæ£€æŸ¥ï¼šinitiating é˜¶æ®µé¿å…"æˆ‘ä»¬å¾ˆç†Ÿ/ä½ åº”è¯¥â€¦"
    # ==========================================
    if stage == "initiating":
        # initiating é˜¶æ®µï¼šé¿å…è¿‡åº¦æ¨è¿›
        inappropriate_patterns = [
            "æˆ‘ä»¬å¾ˆç†Ÿ", "æˆ‘ä»¬åº”è¯¥", "ä½ åº”è¯¥", "ä½ å¿…é¡»", "ä½ å¾—",
            "å’±ä»¬", "å’±ä¿©", "å’±", "ä¸€èµ·", "æˆ‘ä»¬",
            "ä½ å¿ƒé‡Œ", "ä½ å†…å¿ƒ", "ä½ çœŸå®", "ä½ çœŸæ­£",
            "æ·±æŒ–", "æ·±å…¥", "éšç§", "ç§˜å¯†",
        ]
        
        inappropriate_count = sum(1 for pattern in inappropriate_patterns if pattern in all_text)
        
        if inappropriate_count > 0:
            # initiating é˜¶æ®µå‡ºç°ä¸å½“æ¨è¿›ï¼Œæ‰£åˆ†
            penalty = min(0.6, inappropriate_count * 0.15)
            base_score -= penalty
    
    # ==========================================
    # 3. æ£€æŸ¥ pacing_notes ä¸­çš„ç¦å¿Œé¡¹
    # ==========================================
    pacing_notes = stage_targets.get("pacing_notes", [])
    if isinstance(pacing_notes, list):
        for note in pacing_notes:
            note_str = str(note).lower()
            # æ£€æŸ¥æ˜¯å¦åŒ…å«"ä¸è¦"ã€"ç¦æ­¢"ã€"é¿å…"ç­‰ç¦å¿Œè¯
            if any(keyword in note_str for keyword in ["ä¸è¦", "ç¦æ­¢", "é¿å…", "ä¸èƒ½", "ä¸åº”"]):
                # æå–ç¦å¿Œå†…å®¹ï¼ˆç®€å•æå–ï¼‰
                if "è¿‡åº¦" in note_str or "çªç„¶" in note_str:
                    # æ£€æŸ¥æ˜¯å¦è¿å
                    if "è¿‡åº¦" in note_str and ("äº²å¯†" in all_text or "æ·±æŒ–" in all_text):
                        base_score -= 0.2
                    if "çªç„¶" in note_str and ("æˆ‘ä»¬" in all_text or "åº”è¯¥" in all_text):
                        base_score -= 0.15
    
    # ==========================================
    # 4. æ ¹æ® violation_sensitivity è°ƒæ•´åˆ†æ•°
    # ==========================================
    # violation_sensitivity è¶Šé«˜ï¼Œå¯¹è¶Šç•Œè¡Œä¸ºè¶Šæ•æ„Ÿ
    if max_violation > 0.0:
        sensitivity_penalty = max_violation * violation_sensitivity * 0.3
        base_score -= sensitivity_penalty
    
    return _clamp(base_score, 0.0, 1.0)


def soft_score_heuristic(
    state: Dict[str, Any],
    reply_plan: ReplyPlan,
    processor_plan: ProcessorPlan,
    requirements: Dict[str, Any],
) -> Dict[str, float]:
    """
    Rule-based soft scoring: mode consistency + must_have coverage + plan_coverage + style_distance.
    å»æ‰"å»ºè®®è¯å¥–åŠ±"ï¼Œæ”¹ä¸º mode ä¸€è‡´æ€§æ£€æŸ¥ã€‚
    æ–°å¢ plan_coverage å’Œ style_distance ç»´åº¦ã€‚
    """
    msgs = processor_plan.get("messages") or []
    final_response = state.get("final_response") or ""
    
    # è·å– mode_id
    mode = state.get("current_mode")
    mode_id = None
    if isinstance(mode, dict):
        mode_id = mode.get("id")
    elif mode:
        mode_id = getattr(mode, "id", None)
    mode_id = mode_id or "normal_mode"
    
    score: Dict[str, float] = {
        "mode_consistency": 0.0,
        "must_have_coverage": 1.0,
        "plan_coverage": 1.0,
        "style_distance": 1.0,
        "stage_fit_heur": 1.0,
    }
    
    # è®°å½•å¯å‘å¼è¯„åˆ†è¿‡ç¨‹
    log_computation(
        "Evaluator",
        "å¯å‘å¼è½¯è¯„åˆ† (Heuristic Soft Score)",
        inputs={
            "mode_id": mode_id,
            "messages_count": len(msgs),
            "first_message": str(msgs[0])[:100] if msgs else "",
            "final_response": final_response[:100],
        },
    )

    # ==========================================
    # (a) mode_consistency (0..1)
    # ==========================================
    max_messages = int(requirements.get("max_messages", 5) or 5)
    max_message_len = int(requirements.get("max_message_len", 200) or 200)
    first = str(msgs[0] or "").strip() if msgs else ""
    first_len = len(first)
    msg_count = len(msgs)
    
    if mode_id == "normal_mode":
        # normalï¼šé¦–æ¡é•¿åº¦è½åœ¨ [8, max_message_len] ä¸”æ¶ˆæ¯æ•° â‰¤ max_messages â†’ é«˜åˆ†
        if 8 <= first_len <= max_message_len and msg_count <= max_messages:
            score["mode_consistency"] = 1.0
        elif first_len < 8:
            # é¦–æ¡å¤ªçŸ­ï¼ŒæŒ‰æ¯”ä¾‹æ‰£åˆ†
            score["mode_consistency"] = max(0.0, first_len / 8.0)
        elif first_len > max_message_len:
            # é¦–æ¡å¤ªé•¿ï¼Œæ‰£åˆ†
            score["mode_consistency"] = max(0.0, 1.0 - (first_len - max_message_len) / max_message_len)
        elif msg_count > max_messages:
            # æ¶ˆæ¯æ•°è¶…é™ï¼Œæ‰£åˆ†
            score["mode_consistency"] = max(0.0, 1.0 - (msg_count - max_messages) / max_messages)
        else:
            score["mode_consistency"] = 0.7  # å…¶ä»–æƒ…å†µä¸­ç­‰åˆ†æ•°
    
    elif mode_id == "cold_mode":
        # coldï¼šé¦–æ¡é•¿åº¦è½åœ¨ [1, 80] ä¸”æ¶ˆæ¯æ•°==1 â†’ é«˜åˆ†ï¼›å¦‚æœé•¿ç¯‡è§£é‡Š â†’ ç›´æ¥æ‰£åˆ†
        total_len = sum(len(str(m)) for m in msgs)
        if msg_count == 1 and 1 <= first_len <= 80:
            score["mode_consistency"] = 1.0
        elif msg_count == 1 and first_len > 80:
            # å•æ¡ä½†å¤ªé•¿ï¼Œæ‰£åˆ†
            score["mode_consistency"] = max(0.0, 1.0 - (first_len - 80) / 200.0)
        elif msg_count > 1:
            # å¤šæ¡æ¶ˆæ¯ï¼ˆé•¿ç¯‡è§£é‡Šï¼‰ï¼Œç›´æ¥æ‰£åˆ†
            score["mode_consistency"] = max(0.0, 0.3 - (msg_count - 1) * 0.1)
        elif total_len > 150:
            # æ€»é•¿åº¦è¿‡é•¿ï¼ˆé•¿ç¯‡è§£é‡Šï¼‰ï¼Œæ‰£åˆ†
            score["mode_consistency"] = max(0.0, 0.5 - (total_len - 150) / 300.0)
        else:
            score["mode_consistency"] = 0.8  # å…¶ä»–æƒ…å†µä¸­ç­‰åˆ†æ•°
    
    elif mode_id == "mute_mode":
        # muteï¼šmessages==0 æˆ– final_response ä¸ºç©º/"â€¦" â†’ é«˜åˆ†
        if msg_count == 0 or (final_response.strip() == "" or final_response.strip() == "â€¦" or final_response.strip() == "..."):
            score["mode_consistency"] = 1.0
        elif msg_count == 1 and len(first) <= 3:
            # æçŸ­å›å¤ï¼ˆå¦‚"ã€‚"ã€"..."ï¼‰ï¼Œä¹Ÿå¯ä»¥æ¥å—
            score["mode_consistency"] = 0.9
        else:
            # æœ‰å®é™…å†…å®¹ï¼Œæ‰£åˆ†
            score["mode_consistency"] = max(0.0, 0.5 - len(final_response) / 100.0)
    
    else:
        # æœªçŸ¥ modeï¼Œé»˜è®¤ä¸­ç­‰åˆ†æ•°
        score["mode_consistency"] = 0.5
    
    score["mode_consistency"] = _clamp(score["mode_consistency"], 0.0, 1.0)
    
    # ==========================================
    # (b) must_have_coverage (0..1)ï¼ˆä»…å½“ must_have_policy == "soft" æ—¶è®¡ç®—ï¼‰
    # ==========================================
    must_have = requirements.get("must_have") or []
    must_have_policy = str(requirements.get("must_have_policy", "soft"))
    
    if isinstance(must_have, list) and must_have and must_have_policy == "soft":
        # ä½¿ç”¨å…³é”®è¯åŒ…å«æ–¹æ³•ï¼ˆæ¯æ¡ must_have æ‹† 2~4 ä¸ªå…³é”®è¯ï¼‰
        joined = "\n".join([str(x) for x in msgs]).lower()
        covered = 0
        total = len(must_have)
        
        for need in must_have:
            s = str(need or "").strip()
            if not s:
                continue
            
            # æå–å…³é”®è¯
            keywords = _extract_keywords(s, min_keywords=2, max_keywords=4)
            
            # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€åŠå…³é”®è¯åœ¨ joined ä¸­
            matched_keywords = sum(1 for kw in keywords if kw.lower() in joined)
            if matched_keywords >= max(1, len(keywords) // 2):
                covered += 1
        
        if total > 0:
            coverage_ratio = covered / total
            score["must_have_coverage"] = coverage_ratio
        else:
            score["must_have_coverage"] = 1.0
    else:
        # must_have_policy == "none" æˆ–æ²¡æœ‰ must_haveï¼Œä¸æ£€æŸ¥ï¼ˆcold/mute ä¸‹ç›´æ¥ç½® 1.0ï¼‰
        score["must_have_coverage"] = 1.0
    
    score["must_have_coverage"] = _clamp(score["must_have_coverage"], 0.0, 1.0)
    
    # ==========================================
    # (c) plan_coverage (0..1)ï¼šå†…å®¹å±‚æ˜¯å¦ç¬¦åˆ reasoner çš„ plan_goals
    # ==========================================
    plan_goals = requirements.get("plan_goals", {})
    if isinstance(plan_goals, dict):
        score["plan_coverage"] = _compute_plan_coverage(msgs, plan_goals)
    else:
        score["plan_coverage"] = 1.0  # æ²¡æœ‰ plan_goalsï¼Œé»˜è®¤æ»¡åˆ†
    
    score["plan_coverage"] = _clamp(score["plan_coverage"], 0.0, 1.0)
    
    # ==========================================
    # (d) style_distance (0..1)ï¼šè¡¨è¾¾å±‚æ˜¯å¦ç¬¦åˆ style 12 ç»´ç›®æ ‡
    # ==========================================
    style_targets = requirements.get("style_targets", {})
    if isinstance(style_targets, dict) and style_targets:
        score["style_distance"] = _compute_style_distance(msgs, style_targets)
    else:
        score["style_distance"] = 1.0  # æ²¡æœ‰ style_targetsï¼Œé»˜è®¤æ»¡åˆ†
    
    score["style_distance"] = _clamp(score["style_distance"], 0.0, 1.0)
    
    # ==========================================
    # (e) stage_fit_heur (0..1)ï¼šé˜¶æ®µé€‚é…åº¦
    # ==========================================
    stage_targets = requirements.get("stage_targets", {})
    detection_signals = state.get("detection_signals", {})
    if isinstance(stage_targets, dict) and stage_targets:
        score["stage_fit_heur"] = _compute_stage_fit_heur(msgs, stage_targets, detection_signals)
    else:
        score["stage_fit_heur"] = 1.0  # æ²¡æœ‰ stage_targetsï¼Œé»˜è®¤æ»¡åˆ†
    
    score["stage_fit_heur"] = _clamp(score["stage_fit_heur"], 0.0, 1.0)
    
    # ==========================================
    # overall_heurï¼ˆcheap eval çš„â€œç²—ç­›ä¿¡å·â€ï¼‰
    # - must_have_coverage / plan_coverage éƒ½æ˜¯å…³é”®è¯è¿‘ä¼¼ï¼Œå®¹æ˜“æ¨åŠ¨â€œæŠ•å–‚å¼è¾“å‡ºâ€ï¼Œå› æ­¤é™æƒ
    # - mode_consistency / stage_fit_heur æ›´åç»“æ„ä¸è¡Œä¸ºçº¦æŸï¼Œä½œä¸ºç²—ç­›æ›´ç¨³
    # ==========================================
    overall_heur = (
        0.45 * score["mode_consistency"] +
        0.05 * score["must_have_coverage"] +
        0.05 * score["plan_coverage"] +
        0.15 * score["style_distance"] +
        0.30 * score["stage_fit_heur"]
    )
    
    log_computation(
        "Evaluator",
        "å¯å‘å¼è½¯è¯„åˆ†ç»“æœ",
        outputs={
            "score_breakdown": score,
            "overall_heur": overall_heur,
        },
    )
    
    # ä¸ºäº†å…¼å®¹æ€§ï¼Œæ·»åŠ  overall å­—æ®µ
    score["overall"] = overall_heur
    
    return score


CHOREO_SCORER_SYSTEM = """ä½ æ˜¯"æ‹ŸäººèŠ‚å¥è¯„å®¡"(ChoreographyEvaluator)ã€‚
ä½ çš„é‡ç‚¹ä¸æ˜¯æ£€æŸ¥æ‹†å¥åˆä¸åˆè§„ï¼Œè€Œæ˜¯åˆ¤æ–­ï¼šè¿™å¥—å¤šæ¶ˆæ¯ç¼–æ’ï¼ˆå†…å®¹ç»“æ„+èŠ‚å¥+å»¶è¿Ÿ+äº’åŠ¨åŠ¨ä½œï¼‰æ˜¯å¦ç¬¦åˆå½“å‰åœºæ™¯ä¸å…³ç³»å‚æ•°ä¸‹çš„æ‹Ÿäººéœ€æ±‚ï¼Œå¹¶è¾“å‡º**å¯ç”¨äºé€‰æ‹©å‡½æ•°**çš„ç»“æ„åŒ–è¯„åˆ†ä¸è¯æ®ã€‚

ä½ å°†çœ‹åˆ°ï¼šmemory(æ‘˜è¦+æ£€ç´¢)ã€state æ‘˜è¦ã€é£æ ¼ç”»åƒã€ç¡¬çº¦æŸã€ReplyPlanï¼ˆå« must_cover_mapï¼‰ã€ä»¥åŠæœ€ç»ˆå°†å‘é€çš„ messages[] / delays[] / actions[]ã€‚

è¯·ä¸¥æ ¼è¾“å‡º JSONï¼ˆä¸è¦å¤šä½™æ–‡å­—ï¼‰ï¼š
{
  "score_breakdown": {
    "scene_fit": 0.0,
    "first_message_strategy": 0.0,
    "pacing_match_stage_style": 0.0,
    "speech_act_allocation": 0.0,
    "voice_consistency": 0.0,
    "conversation_feel": 0.0,

    "assistantiness": 0.0,
    "immersion_break": 0.0,
    "plan_alignment": 0.0,
    "style_adherence": 0.0,
    "stage_fit": 0.0,

    "persona_consistency": 0.0,
    "relationship_fit": 0.0,
    "memory_faithfulness": 0.0,
    "memory_integration": 0.0,
    "mode_behavior_fit": 0.0
  },
  "overall_score": 0.0,
  "improvement_notes": ["...","..."],

  "plan_alignment_details": [
    {"point": "è¦ç‚¹", "covered": true, "message_id": "m1", "evidence": "åŸæ–‡ç‰‡æ®µ"}
  ],
  "style_dim_report": {
    "verbal_length": {"target": 0.3, "observed": 0.5, "delta": 0.2, "note": "ä¸ºä½•"}
  },
  "stage_act_report": {
    "stage": "initiating",
    "allowed_acts": ["answer","clarify"],
    "forbidden_acts": ["deep_probe"],
    "allocations": [{"message_id":"m1","act":"answer","ok":true,"evidence":"..."}],
    "violations": [{"type":"deep_probe","message_id":"m2","evidence":"..."}]
  },
  "memory_report": {
    "fabricated_claims": [{"claim":"...","evidence":"...","why":"memoryé‡Œæ²¡æœ‰"}],
    "unused_retrieval": [{"memory":"...","why":"æœ¬è½®ç›¸å…³ä½†æ²¡ç”¨"}],
    "privacy_overreach": [{"evidence":"...","why":"å…³ç³»é˜¶æ®µ/äº²å¯†åº¦ä¸å…è®¸"}]
  }
}

è¯„åˆ†èŒƒå›´ï¼š0.0~1.0ã€‚overall_score æ˜¯ breakdown çš„åŠ æƒå¹³å‡ï¼ˆä½ å¯è‡ªè¡Œæƒè¡¡ï¼Œä½†è¦åˆç†ï¼‰ã€‚

**å…³é”®è¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š**
1) **assistantiness** å¿…é¡»åŒ…å«ï¼š0=åƒçœŸäººæœ‹å‹ï¼Œ1=åƒAIåŠ©æ‰‹/å®¢æœã€‚è‹¥ assistantiness>0.5ï¼Œåˆ™ overall_score å¿…é¡» <0.3ã€‚
2) **immersion_break** å¿…é¡»åŒ…å«ï¼š0=å®Œå…¨å…¥æˆï¼Œ1=æ˜æ˜¾â€œå…ƒè¯è¯­/å‡ºæˆ/åœ¨è§£é‡Šè®¾å®šâ€ã€‚è‹¥ immersion_break>0.2ï¼ˆä¾‹å¦‚å‡ºç°â€œè®¾å®š/äººè®¾/è™šæ‹Ÿ/ç³»ç»Ÿ/æ¨¡å‹/ä½œä¸ºä¸€ä¸ªâ€¦â€ï¼‰ï¼Œåˆ™ overall_score å¿…é¡» <0.3ã€‚
3) **plan_alignment/style_adherence/stage_fit** å¿…é¡»åŒ…å«ä¸”ä¸èƒ½çœç•¥ã€‚
4) plan_alignment ä¸èƒ½åªç»™ overallï¼Œå¿…é¡»è¾“å‡º plan_alignment_detailsï¼šå¯¹ plan_goals.must_cover_points é€æ¡å¯¹é½ï¼Œæ ‡æ³¨è¦†ç›–åœ¨å“ªæ¡ message_idï¼Œå¹¶ç»™ evidenceã€‚
5) style_adherence ä¸èƒ½åªç»™ overallï¼Œå¿…é¡»è¾“å‡º style_dim_reportï¼šè‡³å°‘è¦†ç›– style_targets ä¸­å‡ºç°çš„ç»´åº¦ï¼ˆå°½é‡å…¨ 12 ç»´ï¼‰ã€‚
6) stage_fit éœ€è¦ç»“åˆ stage_targetsï¼ˆå°¤å…¶ pacing_notesã€allowed_acts/forbidden_acts è‹¥æä¾›ï¼‰è¾“å‡º stage_act_reportï¼Œè¯†åˆ«â€œè¡Œä¸ºç±»å‹è¶Šç•Œâ€ï¼ˆä¾‹å¦‚ initiating é˜¶æ®µé€¼è‡ªæ›/é€¼æ‰¿è¯º/å…³ç³»æ¨è¿›ï¼‰ã€‚
7) memory_faithfulnessï¼šå¦‚æœå›å¤æš—ç¤ºâ€œæˆ‘è®°å¾—ä½ ä¸Šæ¬¡/ä½ ä¹‹å‰è¯´è¿‡â€¦â€ä½† memory(æ‘˜è¦+æ£€ç´¢)é‡Œæ²¡æœ‰è¯æ®ï¼Œå¿…é¡»æ‰£åˆ†å¹¶å†™å…¥ memory_report.fabricated_claimsã€‚
""".strip()


def soft_score_via_llm(
    state: Dict[str, Any],
    llm_invoker: Any,
    reply_plan: ReplyPlan,
    processor_plan: ProcessorPlan,
    requirements: Dict[str, Any],
) -> Optional[Tuple[float, Dict[str, float], List[str], Dict[str, Any]]]:
    """LLM soft scoring, using the same memory passing rules.

    Returns (overall_score, score_breakdown, improvement_notes, llm_details).
    """
    if llm_invoker is None:
        return None

    system_memory = build_system_memory_block(state)
    style_profile = state.get("style_profile") or state.get("llm_instructions") or {}
    snapshot = summarize_state_for_planner(state)

    system_prompt = f"""{CHOREO_SCORER_SYSTEM}

## Memory (Summary + Retrieved)
{system_memory}

## State Snapshot
{snapshot}

## Style Profile
{safe_text(style_profile)}

## Requirements (Checklist)
{safe_text(requirements)}
""".strip()

    msgs = processor_plan.get("messages") or []
    delays = processor_plan.get("delays") or []
    actions = processor_plan.get("actions") or []
    user_input = safe_text(state.get("external_user_text") or state.get("user_input"))
    strategy = safe_text(state.get("response_strategy"))

    # æå– plan_goalsã€style_targetsã€stage_targetsã€mode_behavior_targets ç”¨äº prompt
    plan_goals = requirements.get("plan_goals", {})
    style_targets = requirements.get("style_targets", {})
    stage_targets = requirements.get("stage_targets", {})
    mode_behavior_targets = requirements.get("mode_behavior_targets", [])
    
    plan_goals_text = ""
    if isinstance(plan_goals, dict):
        must_cover = plan_goals.get("must_cover_points", [])
        avoid_points = plan_goals.get("avoid_points", [])
        if must_cover or avoid_points:
            plan_goals_text = f"""
å¿…é¡»è¦†ç›–çš„æ ¸å¿ƒè¦ç‚¹ï¼ˆplan_goals.must_cover_pointsï¼‰ï¼š
{chr(10).join([f"- {p}" for p in must_cover[:10]]) if must_cover else "ï¼ˆæ— ï¼‰"}

åº”é¿å…çš„è¦ç‚¹ï¼ˆplan_goals.avoid_pointsï¼‰ï¼š
{chr(10).join([f"- {p}" for p in avoid_points[:10]]) if avoid_points else "ï¼ˆæ— ï¼‰"}"""
    
    style_targets_text = ""
    if isinstance(style_targets, dict) and style_targets:
        style_targets_text = f"""
é£æ ¼ç›®æ ‡ï¼ˆstyle_targetsï¼‰ï¼š
{chr(10).join([f"- {k}: {v:.2f}" for k, v in list(style_targets.items())[:10]])}"""
    
    stage_targets_text = ""
    if isinstance(stage_targets, dict):
        stage = stage_targets.get("stage", "")
        pacing_notes = stage_targets.get("pacing_notes", [])
        violation_sensitivity = stage_targets.get("violation_sensitivity", 0.7)
        if stage or pacing_notes:
            stage_targets_text = f"""
å½“å‰å…³ç³»é˜¶æ®µï¼ˆstage_targetsï¼‰ï¼š
- stage: {stage}
- violation_sensitivity: {violation_sensitivity:.2f}
- pacing_notesï¼ˆé˜¶æ®µèŠ‚å¥è¦æ±‚ï¼‰ï¼š
{chr(10).join([f"  - {note}" for note in pacing_notes[:5]]) if pacing_notes else "  ï¼ˆæ— ï¼‰"}"""

    mode_behavior_text = ""
    if isinstance(mode_behavior_targets, list) and mode_behavior_targets:
        mode_behavior_text = f"""
æ¨¡å¼è¡Œä¸ºç­–ç•¥ç›®æ ‡ï¼ˆmode_behavior_targetsï¼‰ï¼š
{chr(10).join([f"- {str(x)}" for x in mode_behavior_targets[:6]])}"""
    
    task = f"""è¯·å¯¹è¿™å¥—"æœ€ç»ˆå°†å‘é€çš„å¤šæ¶ˆæ¯ç¼–æ’"è¿›è¡Œæ‹ŸäººèŠ‚å¥è¯„åˆ†ï¼Œå¹¶ç»™å‡ºé€æ¡å¯¹é½è¯æ®ï¼ˆç”¨äºé€‰æ‹©å‡½æ•°ï¼‰ã€‚

ç”¨æˆ·è¾“å…¥ï¼š
{user_input}

å¯¼æ¼”ç­–ç•¥ï¼ˆreasonerï¼‰ï¼š
{strategy}

ReplyPlanï¼ˆç¼–æ’æ„å›¾ä¸ç†ç”±ï¼Œå« must_cover_map / messages_countï¼‰ï¼š
{safe_text(reply_plan)}

æœ€ç»ˆ messages[]ï¼š
{safe_text(msgs)}

æœ€ç»ˆ delays[]ï¼š
{safe_text(delays)}

æœ€ç»ˆ actions[]ï¼š
{safe_text(actions)}
{plan_goals_text}
{style_targets_text}
{stage_targets_text}
{mode_behavior_text}

è¯·ä¸¥æ ¼è¾“å‡º JSON æ ¼å¼ï¼ˆä¸å‡†çœç•¥ score_breakdown ä¸­çš„ plan_alignment/style_adherence/stage_fit/assistantiness ç­‰å…³é”®ç»´åº¦ï¼‰ï¼Œå¹¶é¢å¤–ç»™å‡ºï¼š
- plan_alignment_detailsï¼ˆé€æ¡ must_cover å¯¹é½ + message_id å®šä½ + evidenceï¼‰
- style_dim_reportï¼ˆé€ç»´åå·®ï¼Œå°½é‡è¦†ç›– 12 ç»´ï¼‰
- stage_act_reportï¼ˆè¡Œä¸ºç±»å‹åˆ†é…/è¶Šç•Œï¼‰
- memory_reportï¼ˆç¼–é€ è®°å¿†/æœªç”¨æ£€ç´¢/éšç§è¶Šç•Œï¼‰
""".strip()

    body_messages = get_chat_buffer_body_messages(state, limit=20)
    
    # è®°å½• LLM è½¯è¯„åˆ†æç¤ºè¯å’Œå‚æ•°
    log_prompt_and_params(
        "Evaluator (LLM Soft Scorer)",
        system_prompt=system_prompt,
        user_prompt=task,
        messages=body_messages,
        params={
            "user_input": user_input,
            "strategy": strategy,
            "reply_plan": str(reply_plan)[:300] + "..." if len(str(reply_plan)) > 300 else str(reply_plan),
            "messages": [str(m)[:100] for m in msgs[:3]],
            "delays": delays,
            "actions": actions,
        }
    )
    
    try:
        resp = llm_invoker.invoke(
            [SystemMessage(content=system_prompt), *body_messages, HumanMessage(content=task)]
        )
        content = getattr(resp, "content", "") or ""
        data = parse_json_from_llm(content)
        if not isinstance(data, dict):
            return None
        
        # è®°å½• LLM å“åº”
        log_llm_response("Evaluator (LLM Soft Scorer)", resp, parsed_result=data)
        bd = data.get("score_breakdown") if isinstance(data.get("score_breakdown"), dict) else {}
        overall = float(data.get("overall_score", 0.0) or 0.0)
        notes = data.get("improvement_notes") if isinstance(data.get("improvement_notes"), list) else []
        details: Dict[str, Any] = {}
        for key in ["plan_alignment_details", "style_dim_report", "stage_act_report", "memory_report"]:
            if key in data:
                details[key] = data.get(key)
        breakdown: Dict[str, float] = {}
        for k, v in bd.items():
            try:
                breakdown[str(k)] = float(v)
            except Exception:
                continue
        
        # ç¡®ä¿åŒ…å« plan_alignmentã€style_adherenceã€stage_fit ä¸‰é¡¹
        # å¦‚æœ LLM æ²¡æœ‰è¾“å‡ºï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5
        if "plan_alignment" not in breakdown:
            breakdown["plan_alignment"] = 0.5
            notes.append("âš  LLM æœªè¾“å‡º plan_alignmentï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5")
        if "style_adherence" not in breakdown:
            breakdown["style_adherence"] = 0.5
            notes.append("âš  LLM æœªè¾“å‡º style_adherenceï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5")
        if "stage_fit" not in breakdown:
            breakdown["stage_fit"] = 0.5
            notes.append("âš  LLM æœªè¾“å‡º stage_fitï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5")
        if "assistantiness" not in breakdown:
            # å…³é”®ç»´åº¦ç¼ºå¤±æ—¶é»˜è®¤åä¿å®ˆï¼ˆæ›´åƒåŠ©æ‰‹ï¼‰ï¼Œé¿å…è¯¯æ—©é€€/è¯¯é€‰
            breakdown["assistantiness"] = 0.8
            notes.append("âš  LLM æœªè¾“å‡º assistantinessï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.8ï¼ˆä¿å®ˆæƒ©ç½šï¼‰")

        # å‡ºæˆ/å…ƒè¯è¯­ï¼šè‹¥ç¼ºå¤±é»˜è®¤ä¸º 0ï¼›ä½†è‹¥æ–‡æœ¬å‘½ä¸­â€œè®¾å®š/äººè®¾/è™šæ‹Ÿ/ç³»ç»Ÿ/æ¨¡å‹/ä½œä¸ºä¸€ä¸ªâ€¦â€åˆ™å¼ºåˆ¶æ‹‰æ»¡
        if "immersion_break" not in breakdown:
            breakdown["immersion_break"] = 0.0
        try:
            all_text = "\n".join([str(m) for m in msgs])
            if any(x in all_text for x in ("è®¾å®š", "äººè®¾", "è™šæ‹Ÿ", "è™šæ„", "è§’è‰²", "å‰§æœ¬", "é…ç½®", "æ¨¡å‹", "ç³»ç»Ÿ", "ä½œä¸ºä¸€ä¸ª")):
                breakdown["immersion_break"] = max(float(breakdown.get("immersion_break", 0.0) or 0.0), 1.0)
        except Exception:
            pass

        # å…³ç³»/äººè®¾/è®°å¿†ç›¸å…³ï¼šè‹¥ç¼ºå¤±åˆ™ç»™ä¸­æ€§é»˜è®¤å¹¶è®°å½•ï¼ˆè¿™äº›ç»´åº¦ç”¨äºé•¿æœŸä¸€è‡´æ€§ï¼‰
        for k in ["persona_consistency", "relationship_fit", "memory_faithfulness", "memory_integration", "mode_behavior_fit"]:
            if k not in breakdown:
                breakdown[k] = 0.5
                notes.append(f"âš  LLM æœªè¾“å‡º {k}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5")
        
        # å¼ºåˆ¶è§„åˆ™ï¼šassistantiness é«˜æ—¶ä¸å¾—ç»™é«˜ overallï¼ˆé¿å…â€œåŠ©æ‰‹å‘³â€å€™é€‰è¢«é€‰ä¸­/æ—©é€€ï¼‰
        try:
            a = float(breakdown.get("assistantiness", 0.0) or 0.0)
        except Exception:
            a = 0.0
        if a > 0.5 and overall > 0.3:
            overall = 0.28
            notes.append(f"âš  assistantiness={a:.2f}>0.5ï¼Œå¼ºåˆ¶ overall_score<=0.3ï¼ˆclampåˆ°0.28ï¼‰")

        # å¼ºåˆ¶è§„åˆ™ï¼šimmersion_break é«˜æ—¶ä¸å¾—ç»™é«˜ overallï¼ˆé¿å…â€œè®¾å®š/äººè®¾/è™šæ‹Ÿâ€ç­‰å‡ºæˆè¯æœ¯è¢«å¥–åŠ±ï¼‰
        try:
            ib = float(breakdown.get("immersion_break", 0.0) or 0.0)
        except Exception:
            ib = 0.0
        if ib > 0.2 and overall > 0.3:
            overall = 0.28
            notes.append(f"âš  immersion_break={ib:.2f}>0.2ï¼Œå¼ºåˆ¶ overall_score<=0.3ï¼ˆclampåˆ°0.28ï¼‰")

        overall = _clamp(overall, 0.0, 1.0)
        return overall, breakdown, [str(x) for x in notes if str(x).strip()], details
    except Exception:
        return None


def evaluate_candidate(
    state: Dict[str, Any],
    reply_plan: ReplyPlan,
    processor_plan: ProcessorPlan,
    requirements: Dict[str, Any],
    *,
    llm_soft_scorer: Any = None,
) -> SimReport:
    failures = hard_gate(processor_plan, requirements)

    # é¢å¤–ç¡¬é—¨æ§›ï¼šReplyPlan çš„ speech_act è‹¥ä¸ºâ€œå»ºè®®â€ï¼Œä½†ç”¨æˆ·æœªæ˜ç¡®è¦å»ºè®®ï¼Œåˆ™ç›´æ¥åˆ¤è´Ÿï¼ˆè§„åˆ’å±‚åç½®çš„å…œåº•ï¼‰
    try:
        user_asks_advice = bool(requirements.get("user_asks_advice", False))
        sa = str((reply_plan or {}).get("speech_act") or "").strip()
        if (not user_asks_advice) and sa in ("å»ºè®®", "advice"):
            failures.append(
                {
                    "id": "unsolicited_advice",
                    "reason": f"speech_act='{sa}' ä½†ç”¨æˆ·æœªæ˜ç¡®è¦å»ºè®®ï¼ˆè§„åˆ’å±‚éœ€å›åˆ°é—²èŠ/æé—®ï¼‰",
                    "evidence": str(requirements.get("latest_user_text") or "")[:120],
                }
            )
    except Exception:
        pass

    hard_pass = not failures

    heur = soft_score_heuristic(state, reply_plan, processor_plan, requirements)
    # ä½¿ç”¨ overall å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™è®¡ç®—å¹³å‡å€¼
    heur_overall = float(heur.get("overall", sum(heur.values()) / max(1, len(heur))))

    overall = heur_overall
    breakdown = {f"heur_{k}": float(v) for k, v in heur.items()}
    notes: List[str] = []

    llm_res = (
        soft_score_via_llm(state, llm_soft_scorer, reply_plan, processor_plan, requirements)
        if llm_soft_scorer
        else None
    )
    if not llm_soft_scorer:
        llm_status = "skipped"
    elif llm_res:
        llm_status = "ok"
    else:
        llm_status = "failed"
    if llm_res:
        llm_overall, llm_breakdown, llm_notes, llm_details = llm_res
        # è½¯åˆ†æ ¸å¿ƒï¼šLLM ç¼–æ’è¯„åˆ†æƒé‡æ›´é«˜ï¼›heur ä½œä¸ºç¨³å®šè¾…åŠ©
        overall = 0.75 * llm_overall + 0.25 * heur_overall
        
        # å¤„ç† assistantiness ç»´åº¦ï¼šæ ¹æ® mode è°ƒæ•´æƒ©ç½šæƒé‡
        assistantiness = float(llm_breakdown.get("assistantiness", 0.0) or 0.0)
        
        # è·å– mode_id å¹¶è®¾ç½®æƒ©ç½šæƒé‡
        mode = state.get("current_mode")
        mode_id = None
        if isinstance(mode, dict):
            mode_id = mode.get("id")
        elif mode:
            mode_id = getattr(mode, "id", None)
        mode_id = mode_id or "normal_mode"
        
        # æ ¹æ® mode_id è®¾ç½® assistantiness æƒ©ç½šæƒé‡
        if mode_id == "normal_mode":
            w = 1.0
        elif mode_id == "cold_mode":
            w = 0.5  # å†·æ·¡æ¨¡å¼æƒ©ç½šå‡åŠï¼ˆå› ä¸ºå†·æ·¡æœ¬æ¥å°±ä¸éœ€è¦"æœåŠ¡æ„Ÿ"ï¼‰
        else:
            w = 0.0  # mute_mode æˆ–å…¶ä»–æ¨¡å¼ä¸æƒ©ç½š
        
        # åº”ç”¨æƒ©ç½šï¼šoverall -= w * 0.25 * assistantiness
        if w > 0.0 and assistantiness > 0.0:
            penalty = w * 0.25 * assistantiness
            overall = max(0.0, overall - penalty)
            notes.append(f"åŠ©æ‰‹å‘³æ£€æµ‹: assistantiness={assistantiness:.2f}, mode={mode_id}, æƒé‡={w:.1f}, æƒ©ç½š={penalty:.4f}")
        
        breakdown.update({f"llm_{k}": float(v) for k, v in llm_breakdown.items()})
        breakdown["llm_overall"] = float(llm_overall)
        breakdown["assistantiness"] = assistantiness  # æ˜¾å¼è®°å½•
        breakdown["assistantiness_weight"] = w  # è®°å½•å®é™…ä½¿ç”¨çš„æƒé‡
        notes.extend(llm_notes)
        print(f"      [è¯„ä¼°] LLMè½¯åˆ†: {llm_overall:.4f}, å¯å‘å¼: {heur_overall:.4f}, åŠ æƒ: {overall:.4f}, assistantiness: {assistantiness:.2f}, mode: {mode_id}, æƒé‡: {w:.1f}")
        # æ ‡è®°ç»“æ„åŒ–ç»†èŠ‚æ˜¯å¦å­˜åœ¨ï¼ˆä¾¿äºæ—¥å¿—è¯Šæ–­ï¼‰
        breakdown["llm_details_present"] = 1.0 if isinstance(llm_details, dict) and llm_details else 0.0

    # Hard gate penalty: fail-fast ä»å…è®¸ä¿ç•™ soft score ä»¥ä¾¿ debugï¼Œä½† reward è¦æ˜¾è‘—é™ä½
    if not hard_pass:
        overall_before_penalty = overall
        overall = overall * 0.2
        notes.insert(0, "ç¡¬é—¨æ§›æœªé€šè¿‡ï¼šå·²å¤§å¹…æƒ©ç½šæ€»åˆ†ã€‚")
        print(f"      [è¯„ä¼°] âš  ç¡¬é—¨æ§›å¤±è´¥ï¼Œæƒ©ç½š: {overall_before_penalty:.4f} -> {overall:.4f}")

    overall = _clamp(float(overall), 0.0, 1.0)
    found_solution = bool(hard_pass and overall >= 0.55)
    
    # è®°å½•æœ€ç»ˆè¯„ä¼°ç»“æœ
    log_computation(
        "Evaluator",
        "æœ€ç»ˆè¯„ä¼°ç»“æœæ±‡æ€»",
        inputs={
            "hard_pass": hard_pass,
            "heur_overall": heur_overall,
            "llm_overall": llm_res[0] if llm_res else None,
            "llm_status": llm_status,
        },
        outputs={
            "final_score": overall,
            "found_solution": found_solution,
            "score_breakdown": breakdown,
            "failed_checks": failures,
            "improvement_notes": notes[:8],
        },
    )
    
    return {
        "found_solution": found_solution,
        "eval_score": round(overall, 4),
        "failed_checks": failures,
        "score_breakdown": {k: round(float(v), 4) for k, v in breakdown.items()},
        "improvement_notes": notes[:8],
        "llm_status": llm_status,
        "llm_details": llm_res[3] if (llm_res and isinstance(llm_res[3], dict)) else {},
    }
